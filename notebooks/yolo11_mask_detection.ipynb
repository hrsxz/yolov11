{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Create a new YOLO model from scratch\n",
    "# model = YOLO(\"../models/yolo11m.yaml\")\n",
    "\n",
    "# Load a pretrained YOLO model (recommended for training)\n",
    "model = YOLO(r\"D:\\Foester\\initial preparation\\yolov11\\models\\last.pt\")\n",
    "print(\"加载模型:\", model.ckpt_path)\n",
    "\n",
    "# Train the model using the 'coco8.yaml' dataset for 3 epochs\n",
    "results = model.train(data=r\"D:\\Foester\\initial preparation\\yolov11\\data_mask\\data.yaml\",\n",
    "                      epochs=300,\n",
    "                      project=r\"D:\\Foester\\initial preparation\\yolov11\\models\\runs\",\n",
    "                      amp=False,\n",
    "                      batch=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.51  Python-3.11.9 torch-2.5.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,031,574 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\AI\\DefectDetection\\yolov11\\data_mask\\valid\\labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:21<00:00, 10.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         29        162      0.861      0.662      0.787      0.471\n",
      "                  mask         28        142      0.936      0.725      0.876      0.535\n",
      "               no-mask          9         20      0.785        0.6      0.697      0.406\n",
      "Speed: 12.4ms preprocess, 543.5ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\AI\\DefectDetection\\yolov11\\models\\runs\\val2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 加载指定的模型文件\n",
    "model = YOLO(r\"D:\\AI\\DefectDetection\\yolov11\\models\\last.pt\")\n",
    "# Evaluate the model's performance on the validation set\n",
    "results = model.val(data=r\"D:\\AI\\DefectDetection\\yolov11\\data_mask\\data.yaml\",\n",
    "                    project=r\"D:\\AI\\DefectDetection\\yolov11\\models\\runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.51  Python-3.11.9 torch-2.5.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,031,574 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\AI\\DefectDetection\\yolov11\\data_mask\\valid\\labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:20<00:00, 10.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         29        162       0.77      0.826      0.847      0.529\n",
      "                  mask         28        142      0.937      0.817       0.91      0.588\n",
      "               no-mask          9         20      0.603      0.835      0.785      0.471\n",
      "Speed: 9.5ms preprocess, 505.1ms inference, 0.0ms loss, 6.0ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\AI\\DefectDetection\\yolov11\\models\\runs\\val3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 加载指定的模型文件\n",
    "model = YOLO(r\"D:\\AI\\DefectDetection\\yolov11\\models\\best.pt\")\n",
    "# Evaluate the model's performance on the validation set\n",
    "results = model.val(data=r\"D:\\AI\\DefectDetection\\yolov11\\data_mask\\data.yaml\",\n",
    "                    project=r\"D:\\AI\\DefectDetection\\yolov11\\models\\runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Foester\\Einstand_vorbereitung\\yolov11\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 获取当前目录\n",
    "current_directory = os.getcwd()\n",
    "print(current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "D:\\AI\\DefectDetection\\yolov11\\data_mask\\test\\images does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(output_folder, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# save results\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mplotters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_results_and_labels\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfidence_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Foester\\Einstand_vorbereitung\\yolov11\\src\\utils\\plotters.py:76\u001b[0m, in \u001b[0;36mplot_results_and_labels\u001b[1;34m(results, confidence_threshold, output_folder)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_results_and_labels\u001b[39m(\n\u001b[0;32m     71\u001b[0m     results,\n\u001b[0;32m     72\u001b[0m     confidence_threshold: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m,\n\u001b[0;32m     73\u001b[0m     output_folder: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     74\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;66;03m# Iterate through results\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_filename\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Foester\\Einstand_vorbereitung\\yolov11\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32md:\\Foester\\Einstand_vorbereitung\\yolov11\\.venv\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:231\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_model(model)\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:  \u001b[38;5;66;03m# for thread-safe inference\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m# Setup source every time predict is called\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;66;03m# Check if save_dir/ label file exists\u001b[39;00m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_txt:\n",
      "File \u001b[1;32md:\\Foester\\Einstand_vorbereitung\\yolov11\\.venv\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:203\u001b[0m, in \u001b[0;36mBasePredictor.setup_source\u001b[1;34m(self, source)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgsz \u001b[38;5;241m=\u001b[39m check_imgsz(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mimgsz, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstride, min_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# check image size\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    202\u001b[0m )\n\u001b[1;32m--> 203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_inference_source\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvid_stride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvid_stride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39msource_type\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mstream\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mscreenshot\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1000\u001b[39m  \u001b[38;5;66;03m# many images\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo_flag\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;28;01mFalse\u001b[39;00m]))\n\u001b[0;32m    215\u001b[0m ):  \u001b[38;5;66;03m# videos\u001b[39;00m\n",
      "File \u001b[1;32md:\\Foester\\Einstand_vorbereitung\\yolov11\\.venv\\Lib\\site-packages\\ultralytics\\data\\build.py:202\u001b[0m, in \u001b[0;36mload_inference_source\u001b[1;34m(source, batch, vid_stride, buffer)\u001b[0m\n\u001b[0;32m    200\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m LoadPilAndNumpy(source)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 202\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mLoadImagesAndVideos\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvid_stride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvid_stride\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;66;03m# Attach source types to the dataset\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28msetattr\u001b[39m(dataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, source_type)\n",
      "File \u001b[1;32md:\\Foester\\Einstand_vorbereitung\\yolov11\\.venv\\Lib\\site-packages\\ultralytics\\data\\loaders.py:341\u001b[0m, in \u001b[0;36mLoadImagesAndVideos.__init__\u001b[1;34m(self, path, batch, vid_stride)\u001b[0m\n\u001b[0;32m    339\u001b[0m         files\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m((parent \u001b[38;5;241m/\u001b[39m p)\u001b[38;5;241m.\u001b[39mabsolute()))  \u001b[38;5;66;03m# files (relative to *.txt file parent)\u001b[39;00m\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 341\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;66;03m# Define files as images or videos\u001b[39;00m\n\u001b[0;32m    344\u001b[0m images, videos \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: D:\\AI\\DefectDetection\\yolov11\\data_mask\\test\\images does not exist"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "from src.utils import plotters\n",
    "\n",
    "\n",
    "# Load the model\n",
    "model = YOLO(r\".\\models\\mask_detection.pt\")\n",
    "\n",
    "# Prompt user to set confidence threshold\n",
    "# confidence_threshold = float(input(\"Enter confidence threshold (0 to 1): \"))\n",
    "confidence_threshold = 0.4\n",
    "\n",
    "# Inference\n",
    "results = model(r\".\\data_mask\\test\\images\", stream=True)\n",
    "\n",
    "# Create output folder\n",
    "output_folder = r\".\\data_mask\\test\\results\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# save results\n",
    "plotters.plot_results_and_labels(\n",
    "    results, confidence_threshold, output_folder\n",
    ")\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
